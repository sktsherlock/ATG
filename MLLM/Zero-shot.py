import os
import ast
import argparse
import torch
import time
import warnings
import pandas as pd
from PIL import Image
import numpy as np
import dgl
import random
import wandb
from dgl import load_graphs
import networkx as nx
from Library import load_model_and_processor
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score
warnings.filterwarnings("ignore", message="Setting `pad_token_id` to `eos_token_id`")


def set_seed(seed: int):
    os.environ['PYTHONHASHSEED'] = str(seed)  # ç¡®ä¿ Python çš„å“ˆå¸Œè¡Œä¸ºå¯å¤ç°
    random.seed(seed)  # Python å†…ç½®çš„éšæœºç§å­
    np.random.seed(seed)  # NumPy çš„éšæœºç§å­
    torch.manual_seed(seed)  # PyTorch çš„ CPU éšæœºç§å­
    torch.cuda.manual_seed(seed)  # PyTorch çš„ GPU éšæœºç§å­ï¼ˆä»…å½±å“å½“å‰ GPUï¼‰
    torch.cuda.manual_seed_all(seed)  # å½±å“æ‰€æœ‰å¯ç”¨ GPU



def split_dataset(nodes_num, train_ratio, val_ratio):
    np.random.seed(42)
    indices = np.random.permutation(nodes_num)

    train_size = int(nodes_num * train_ratio)
    val_size = int(nodes_num * val_ratio)

    train_ids = indices[:train_size]
    val_ids = indices[train_size:train_size + val_size]
    test_ids = indices[train_size + val_size:]

    return train_ids, val_ids, test_ids



def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Multimodal Node Classification with MLLM and RAG-enhanced inference')
    parser.add_argument('--model_name', type=str, default='meta-llama/Llama-3.2-11B-Vision-Instruct',
                        help='HuggingFaceæ¨¡å‹åç§°æˆ–è·¯å¾„')
    parser.add_argument('--dataset_name', type=str, default='Movies',
                        help='æ•°æ®é›†åç§°ï¼ˆå¯¹åº”Dataç›®å½•ä¸‹çš„å­ç›®å½•åï¼‰')
    parser.add_argument('--base_dir', type=str, default=os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
                        help='é¡¹ç›®æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--max_new_tokens', type=int, default=15,
                        help='ç”Ÿæˆçš„æœ€å¤§tokenæ•°é‡')
    parser.add_argument('--image_ext', type=str, default='.jpg',
                        help='å›¾åƒæ–‡ä»¶æ‰©å±•å')
    parser.add_argument('--neighbor_mode', type=str, default='both', choices=['text', 'image', 'both'],
                        help='é‚»å±…ä¿¡æ¯çš„ä½¿ç”¨æ¨¡å¼ï¼ˆæ–‡æœ¬ã€å›¾åƒæˆ–ä¸¤è€…ï¼‰')
    # æ·»åŠ å‚æ•° upload_image, æ§åˆ¶åœ¨wandbçš„ table ä¸­æ˜¯å¦ä¸Šä¼ å›¾åƒ
    parser.add_argument('--upload_image', type=bool, default=False,
                        help='æ˜¯å¦å°†å›¾åƒä¸Šä¼ åˆ°WandB')
    parser.add_argument('--add_CoT', type=str, default='False',
                        help='æ˜¯å¦æ·»åŠ CoT')
    parser.add_argument('--num_samples', type=int, default=5,
                        help='æµ‹è¯•æ ·æœ¬æ•°é‡')
    parser.add_argument('--num_neighbours', type=int, default=0,
                        help='æœŸæœ›çš„é‚»å±…æ•°')
    parser.add_argument(
        "--train_ratio", type=float, default=0.6, help="training ratio"
    )
    parser.add_argument(
        "--val_ratio", type=float, default=0.2, help="training ratio"
    )
    return parser.parse_args()


class DatasetLoader:
    def __init__(self, args):
        """åˆå§‹åŒ–æ•°æ®é›†åŠ è½½å™¨"""
        self.args = args
        self.data_dir = os.path.join(args.base_dir, 'Data', args.dataset_name)
        self._verify_paths()

    def _verify_paths(self):
        """éªŒè¯å¿…è¦è·¯å¾„æ˜¯å¦å­˜åœ¨"""
        required_files = [
            os.path.join(self.data_dir, f"{self.args.dataset_name}.csv"),
            os.path.join(self.data_dir, f"{self.args.dataset_name}Graph.pt"),
            os.path.join(self.data_dir, f"{self.args.dataset_name}Images")
        ]
        missing = [path for path in required_files if not os.path.exists(path)]
        if missing:
            raise FileNotFoundError(f"Missing required files/directories: {missing}")

    def load_data(self):
        """åŠ è½½æ•°æ®é›†"""
        # åŠ è½½CSVæ•°æ®
        csv_path = os.path.join(self.data_dir, f"{self.args.dataset_name}.csv")
        df = pd.read_csv(csv_path, converters={'neighbors': ast.literal_eval})


        # åŠ è½½å›¾æ•°æ®ï¼ˆDGLæ ¼å¼ï¼‰
        graph_path = os.path.join(self.data_dir, f"{self.args.dataset_name}Graph.pt")
        graph = load_graphs(graph_path)[0][0]

        return df, graph

    def load_image(self, node_id: int) -> Image.Image:
        """åŠ è½½èŠ‚ç‚¹å›¾åƒ"""
        img_path = os.path.join(
            self.data_dir,
            f"{self.args.dataset_name}Images",
            f"{node_id}{self.args.image_ext}"
        )
        if not os.path.exists(img_path):
            raise FileNotFoundError(f"Image not found: {img_path}")
        return Image.open(img_path).convert("RGB")


def get_k_hop_neighbors(nx_graph, node_id, k):
    """
    è·å–æŒ‡å®šä¸­å¿ƒèŠ‚ç‚¹çš„ k-hop é‚»å±…ï¼ˆä¸åŒ…å«ä¸­å¿ƒèŠ‚ç‚¹ï¼‰
    ä½¿ç”¨ NetworkX çš„ single_source_shortest_path_length æ–¹æ³•ã€‚
    """
    neighbors = set()
    for target, distance in nx.single_source_shortest_path_length(nx_graph, node_id).items():
        if 0 < distance <= k:
            neighbors.add(target)
    return list(neighbors)


def build_classification_prompt_with_neighbors(center_text: str, neighbor_texts: list, neighbor_images: list, classes: list, add_cot: bool) -> str:
    """
    Build a RAG-enhanced classification prompt by integrating the center node's text with its neighbors' information.
    """
    if neighbor_images:
        prompt = "These are the images related to the center node and its neighbor nodes.\n"
    else:
        prompt = "This is the image of the center node.\n"
    # 2ï¸âƒ£ **ä¸­å¿ƒèŠ‚ç‚¹æ–‡æœ¬**
    prompt += f"\nDescription of the center node: {center_text}\n"

    if neighbor_texts:
        prompt += "\nBelow are descriptions of the neighbor nodes:\n"
        for idx, n_text in enumerate(neighbor_texts):
            prompt += f"Neighbor {idx+1}: {n_text}\n"

    prompt += f"\nAvailable categories: {', '.join(classes)}.\n"

    if neighbor_texts and neighbor_images:
        prompt += "\nConsidering the multimodal information (both text and image) from the center node and its neighbors, determine the most appropriate category."
    elif neighbor_texts:
        prompt += "\nConsidering the center node's multimodal information and the text information from its neighbors, determine the most appropriate category."
    elif neighbor_images:
        prompt += "\nConsidering the center node's multimodal information and the image information from its neighbors, determine the most appropriate category."
    else:
        prompt += "\nConsidering the center node's multimodal information, determine the most appropriate category."

    if add_cot:
        prompt += "\n\nLet's think step by step."
    # æ·»åŠ è¦æ±‚ä»…è¿”å›å‡†ç¡®çš„ç±»åˆ«åç§°
    prompt += "\nAnswer ONLY with the exact category name."

    return prompt.strip()



def k_hop_neighbor_stats(nx_graph, k):
    """
    è®¡ç®—å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„ k é˜¶é‚»å±…æ•°ç›®çš„ç»Ÿè®¡ä¿¡æ¯ã€‚

    å‚æ•°ï¼š
    - nx_graph: networkx.Graphï¼Œè¾“å…¥çš„æ— å‘å›¾
    - k: intï¼Œè¡¨ç¤ºè®¡ç®— k é˜¶é‚»å±…

    è¿”å›ï¼š
    - stats: dictï¼ŒåŒ…å«æœ€å°å€¼ã€æœ€å¤§å€¼ã€å¹³å‡å€¼ã€ä¸­ä½æ•°ã€æ ‡å‡†å·®
    """
    if nx_graph is None:
        raise ValueError("è¾“å…¥çš„å›¾æ•°æ®ä¸èƒ½ä¸ºç©º")

    all_k_hop_counts = []

    for node in nx_graph.nodes():
        k_hop_neighbors = set(nx.single_source_shortest_path_length(nx_graph, node, cutoff=k).keys())
        k_hop_neighbors.discard(node)  # ç§»é™¤è‡ªèº«
        all_k_hop_counts.append(len(k_hop_neighbors))

    stats = {
        "min": np.min(all_k_hop_counts),
        "max": np.max(all_k_hop_counts),
        "mean": np.mean(all_k_hop_counts),
        "median": np.median(all_k_hop_counts),
        "std": np.std(all_k_hop_counts)
    }

    return stats


def print_k_hop_stats(nx_graph, ks=[1, 2, 3]):
    """æ‰“å° 1, 2, 3 é˜¶é‚»å±…çš„ç»Ÿè®¡ä¿¡æ¯"""
    for k in ks:
        stats = k_hop_neighbor_stats(nx_graph, k)
        print(f"\n{k} é˜¶é‚»å±…ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print(f"  æœ€å°é‚»å±…æ•°: {stats['min']}")
        print(f"  æœ€å¤§é‚»å±…æ•°: {stats['max']}")
        print(f"  å¹³å‡é‚»å±…æ•°: {stats['mean']:.2f}")
        print(f"  ä¸­ä½æ•°: {stats['median']}")
        print(f"  æ ‡å‡†å·®: {stats['std']:.2f}")


def find_isolated_nodes(dgl_graph):
    """åˆ¤æ–­ DGL å›¾æ˜¯å¦å­˜åœ¨å­¤ç«‹ç‚¹ï¼Œå¹¶è¿”å›å­¤ç«‹ç‚¹çš„èŠ‚ç‚¹ ID å’Œæ•°é‡"""
    in_degrees = dgl_graph.in_degrees()
    out_degrees = dgl_graph.out_degrees()

    # è¯†åˆ«å­¤ç«‹ç‚¹ï¼šå…¥åº¦å’Œå‡ºåº¦éƒ½ä¸º 0
    isolated_mask = (in_degrees == 0) & (out_degrees == 0)
    isolated_nodes = torch.nonzero(isolated_mask, as_tuple=True)[0]  # è·å–å­¤ç«‹ç‚¹ ID

    num_isolated_nodes = isolated_nodes.numel()  # å­¤ç«‹ç‚¹çš„æ€»æ•°

    if num_isolated_nodes > 0:
        print(f"å­˜åœ¨ {num_isolated_nodes} ä¸ªå­¤ç«‹ç‚¹")
        print(f"å­¤ç«‹ç‚¹èŠ‚ç‚¹ ID: {isolated_nodes.tolist()}")
    else:
        print("å›¾ä¸­æ²¡æœ‰å­¤ç«‹ç‚¹")

    return isolated_nodes.tolist(), num_isolated_nodes


# def sample_k_hop_neighbors(nx_graph, node_id, k, max_samples):
#     """
#     é‡‡æ · k-hop é‚»å±…èŠ‚ç‚¹ï¼Œä¼˜å…ˆä»ä½é˜¶é‚»å±…ä¸­è·å–ï¼Œè‹¥æ•°é‡ä¸è¶³ï¼Œåˆ™ä»æ›´é«˜é˜¶é‚»å±…è¡¥å……
#     :param nx_graph: networkx å›¾
#     :param node_id: å½“å‰èŠ‚ç‚¹ ID
#     :param k: æœ€é«˜ k-hop
#     :param max_samples: æœŸæœ›çš„é‚»å±…æ•°
#     :return: é‡‡æ ·çš„é‚»å±…èŠ‚ç‚¹ ID åˆ—è¡¨
#     """
#     sampled_neighbors = set()
#     for hop in range(1, k + 1):
#         if len(sampled_neighbors) >= max_samples:
#             break  # å¦‚æœå·²ç»é‡‡æ ·å¤Ÿ max_samples ä¸ªé‚»å±…ï¼Œåˆ™åœæ­¢
#
#         # è·å– hop-hop é‚»å±…
#         neighbors = get_k_hop_neighbors(nx_graph, node_id, hop)
#         neighbors = list(set(neighbors) - sampled_neighbors)  # å»é‡ï¼Œé¿å…é‡å¤é‡‡æ ·
#
#         # éšæœºé‡‡æ ·å‰©ä½™æ‰€éœ€é‚»å±…æ•°
#         num_needed = max_samples - len(sampled_neighbors)
#         sampled_neighbors.update(random.sample(neighbors, min(num_needed, len(neighbors))))
#
#     return list(sampled_neighbors)


def main(args):
    start_time = time.time()  # è®°å½•èµ·å§‹æ—¶é—´
    # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
    dataset_loader = DatasetLoader(args)
    df, dgl_graph = dataset_loader.load_data()

    # é¢„å®šä¹‰è§„åˆ™
    TEXT_COLUMN_RULES = ["text", "caption"]
    LABEL_COLUMN_RULES = ["second_category", "subreddit"]

    # æ ¹æ®è§„åˆ™é€‰æ‹© text_column
    text_column = next((col for col in TEXT_COLUMN_RULES if col in df.columns), None)
    text_label_column = next((col for col in LABEL_COLUMN_RULES if col in df.columns), None)

    # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°åˆé€‚çš„åˆ—
    if text_column is None:
        raise ValueError(f"æ•°æ®é›†ä¸­æœªæ‰¾åˆ°åˆé€‚çš„æ–‡æœ¬åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†åˆ—å: {df.columns}")

    if text_label_column is None:
        raise ValueError(f"æ•°æ®é›†ä¸­æœªæ‰¾åˆ°åˆé€‚çš„æ ‡ç­¾åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†åˆ—å: {df.columns}")

    print(f"ä½¿ç”¨çš„æ–‡æœ¬åˆ—: {text_column}")
    print(f"ä½¿ç”¨çš„æ ‡ç­¾åˆ—: {text_label_column}")

    # ä»CSVä¸­æå–æ‰€æœ‰å”¯ä¸€ç±»åˆ«ï¼Œå¹¶æ’åºï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´é¡ºåºï¼‰
    classes = sorted(df[text_label_column].str.lower().unique())
    # æ„å»ºä¸€ä¸ªä»èŠ‚ç‚¹IDåˆ°èŠ‚ç‚¹æ•°æ®çš„å­—å…¸ï¼Œä¾¿äºåç»­æŸ¥æ‰¾é‚»å±…ä¿¡æ¯
    # å‡è®¾ CSV ä¸­ "id" åˆ—ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦ï¼Œä¸” "text" ä¸ºèŠ‚ç‚¹æè¿°
    node_data_dict = {row["id"]: row for _, row in df.iterrows()}

    isolated_nodes, num_isolated = find_isolated_nodes(dgl_graph)
    print(f"å­¤ç«‹ç‚¹æ•°é‡: {num_isolated}, å­¤ç«‹ç‚¹ ID: {isolated_nodes}")
    # å¦‚æœä½¿ç”¨ RAG å¢å¼ºæ¨ç†ï¼Œè½¬æ¢ DGL å›¾ä¸º NetworkX å›¾
    if args.num_neighbours > 0:
        # # æ·»åŠ åå‘è¾¹ï¼Œè½¬æ¢ä¸ºæ— å‘å›¾
        # srcs, dsts = dgl_graph.all_edges()
        # dgl_graph.add_edges(dsts, srcs)
        dgl_graph.ndata["_ID"] = torch.arange(dgl_graph.num_nodes())

        nx_graph = dgl.to_networkx(dgl_graph, node_attrs=['_ID'])  # æ ¹æ®å®é™…æƒ…å†µè®¾ç½®èŠ‚ç‚¹å±æ€§
    else:
        nx_graph = None
    # print_k_hop_stats(nx_graph)

    model_name = args.model_name  # è¿™é‡Œå¯ä»¥ä¼ å…¥ä½ çš„æ¨¡å‹åç§°
    model, processor = load_model_and_processor(model_name)


    # åˆå§‹åŒ–è®¡æ•°å™¨
    y_true = []
    y_pred = []
    total_samples = 0
    mismatch_count = 0  # ç»Ÿè®¡é¢„æµ‹ç±»åˆ«å®Œå…¨ä¸åŒ¹é…çš„æƒ…å†µ

    # è¿›è¡Œæ•°æ®é›†åˆ’åˆ†
    train_ids, val_ids, test_ids = split_dataset(
        nodes_num=len(df),
        train_ratio=args.train_ratio,
        val_ratio=args.val_ratio,
    )

    selected_ids = test_ids  # è¿™é‡Œå¯ä»¥é€‰æ‹© train_ids, val_ids, æˆ– test_ids
    sample_df = df.iloc[selected_ids]  # ä½¿ç”¨ selected_ids æ¥é€‰æ‹©ç›¸åº”çš„æ•°æ®é›†
    # å¦‚æœ num_samples ä¸º 0ï¼Œä½¿ç”¨å…¨éƒ¨ selected_ids
    num_samples = args.num_samples if args.num_samples > 0 else len(sample_df)
    # è¾“å‡ºç”¨äºè°ƒè¯•
    print(f"Selected {num_samples} samples out of {len(sample_df)} available samples.")
    # ä»æ‰€é€‰çš„å­é›†æ•°æ®ä¸­ï¼Œå†é€‰æ‹©å‰ num_samples ä¸ªæ ·æœ¬
    sample_df = sample_df.head(num_samples)  # é€‰æ‹©å‰ num_samples ä¸ªæ ·æœ¬
    add_CoT = True if str(args.add_CoT).lower() == "true" else False   # æ˜¯å¦æ·»åŠ ç®€å•çš„æ€ç»´é“¾æç¤º
    print(f"Adding Chain of Thought: {add_CoT}")

    if args.upload_image:
        table = wandb.Table(columns=["node_id", "Image", "Neighbor_Images", "input", "ground_truth", "prediction_output",
                                     "predicted_class"])
    else:
        table = wandb.Table(columns=["node_id", "input", "ground_truth", "prediction_output", "predicted_class"])

    set_seed(42)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡ç°

    if args.num_neighbours > 0:
        neighbor_dict = {}  # ç”¨æ¥å­˜å‚¨æ¯ä¸ªèŠ‚ç‚¹çš„é‚»å±… ID åˆ—è¡¨
        max_hop = 3  # æœ€å¤§è·³æ•°
        for node_id in tqdm(sample_df["id"], desc="Fetching neighbors"):
            sampled_neighbors = set()  # ç”¨ set å­˜å‚¨ï¼Œå»é‡
            k = args.num_neighbours  # éœ€è¦çš„é‚»å±…æ•°é‡
            current_hop = 1  # ä» 1-hop å¼€å§‹

            while len(sampled_neighbors) < k and current_hop <= max_hop:
                # è·å–å½“å‰ hop çš„é‚»å±…
                neighbors_at_current_hop = set(nx_graph.neighbors(node_id))  # ä½¿ç”¨ set é˜²æ­¢é‡å¤
                neighbors_at_current_hop.discard(node_id)  # ğŸ”¥ å…³é”®ï¼šå»é™¤è‡ªèº« ID
                sampled_neighbors.update(neighbors_at_current_hop)  # æ·»åŠ æ–°é‚»å±…
                current_hop += 1  # ç»§ç»­å¯»æ‰¾æ›´è¿œçš„é‚»å±…

            # åªä¿ç•™å‰ k ä¸ªé‚»å±…
            neighbor_dict[node_id] = list(sampled_neighbors)[:k]

    for idx, row in tqdm(sample_df.iterrows(), total=sample_df.shape[0], desc="Processing samples"):
        try:
            node_id = row["id"]
            center_text = row[text_column]
            text_label = row[text_label_column].lower()  # æ–‡æœ¬ç±»åˆ«æ ‡ç­¾

            # åŠ è½½å›¾åƒ
            center_image = dataset_loader.load_image(node_id)

            # åˆå§‹åŒ–å­˜å‚¨é‚»å±…æ•°æ®çš„å˜é‡
            neighbor_texts = []
            neighbor_images = []

            # **æ„é€ è¾“å…¥çš„ messages**
            messages = [{"role": "user", "content": [{"type": "image", "image": center_image}]}]

            if args.num_neighbours > 0:
                # è·å–èŠ‚ç‚¹çš„é‚»å±… ID
                sampled_neighbor_ids = neighbor_dict.get(node_id, [])

                for nid in sampled_neighbor_ids:
                    if nid in node_data_dict:
                        if nid == node_id:
                            warnings.warn(
                                f"é‡‡æ ·åˆ°çš„é‚»å±… ID ({nid}) ä¸å½“å‰èŠ‚ç‚¹ ID ({node_id}) ç›¸åŒï¼Œå¯èƒ½å­˜åœ¨è‡ªç¯æˆ–é‡å¤é‡‡æ ·æƒ…å†µï¼")
                        else:
                            node_info = node_data_dict[nid]

                            # å¤„ç†é‚»å±…æ–‡æœ¬
                            if args.neighbor_mode in ["text", "both"]:
                                text = str(node_info.get(text_column, ""))
                                neighbor_texts.append(text)

                            # å¤„ç†é‚»å±…å›¾åƒï¼ˆæ­£ç¡®åŠ è½½ï¼‰
                            if args.neighbor_mode in ["image", "both"]:
                                try:
                                    image = dataset_loader.load_image(nid)  # é€šè¿‡ dataset_loader æ­£ç¡®åŠ è½½é‚»å±…å›¾åƒ
                                    neighbor_images.append(image)
                                except Exception as e:
                                    print(f"åŠ è½½é‚»å±… {nid} çš„å›¾åƒå¤±è´¥: {e}")
                if args.neighbor_mode in ["image", "both"]:
                    for img in neighbor_images:
                        messages[0]["content"].append({"type": "image", "image": img})
                    images = [center_image] + neighbor_images

                # æ„é€ æœ€ç»ˆçš„æç¤ºæ–‡æœ¬
                prompt_text = build_classification_prompt_with_neighbors(center_text, neighbor_texts, neighbor_images, classes, add_CoT)
            else:
                # ä½¿ç”¨åŸºæœ¬æç¤ºï¼Œä¸è¿›è¡Œé‚»å±…å¢å¼º
                prompt_text = build_classification_prompt_with_neighbors(center_text, neighbor_texts, neighbor_images, classes, add_CoT)


            messages[0]["content"].append({"type": "text", "text": prompt_text})

            # **ä½¿ç”¨å¤„ç†å™¨ç”Ÿæˆè¾“å…¥æ–‡æœ¬, å¯¹äºLLaMAï¼ŒLLaVAï¼ŒQwen OK**
            input_text = processor.apply_chat_template(messages, add_generation_prompt=False)

            # **å¤„ç†å›¾åƒå’Œæ–‡æœ¬è¾“å…¥**
            inputs = processor(
                images if args.neighbor_mode in ["image", "both"] and args.num_neighbours > 0 else center_image,  # åªä¼ å›¾åƒæˆ–å•å¼ å›¾
                input_text,
                add_special_tokens=False,
                return_tensors="pt"
            ).to(model.device)


            # æ‰“å°è¾“å…¥çš„å›¾åƒå’Œæ–‡æœ¬ä¿¡æ¯ä»¥è¿›è¡Œè°ƒè¯•
            # print("Input Image:", image)
            # print("Input Text:", input_text)
            # ç”Ÿæˆé¢„æµ‹ç»“æœ
            output = model.generate(**inputs, max_new_tokens=args.max_new_tokens) # temperature=1.0, top_k=50, top_p=0.95
            output_tokens = output[0][len(inputs["input_ids"][0]):]
            prediction = processor.decode(output_tokens, skip_special_tokens=True).strip().lower()
            # prediction = processor.decode(output[0], skip_special_tokens=True).strip().lower()

            # ç®€å•è§£æé¢„æµ‹ç»“æœï¼ŒåŒ¹é…ç±»åˆ«åˆ—è¡¨ä¸­çš„å…³é”®è¯
            # print("Prediction:", prediction)
            predicted_class = next((c for c in classes if c in prediction), None)
            # print("Predicted Class:", predicted_class)

            total_samples += 1
            # è®¡ç®—å®Œå…¨ä¸åŒ¹é…çš„æƒ…å†µ
            if predicted_class is None:  # é¢„æµ‹ç»“æœä¸ç±»åˆ«åˆ—è¡¨å®Œå…¨ä¸åŒ¹é…
                mismatch_count += 1

            # æ”¶é›†çœŸå®å€¼å’Œé¢„æµ‹å€¼
            y_true.append(text_label)
            y_pred.append(predicted_class if predicted_class else "unknown")  # ç”¨ "unknown" ä»£æ›¿æœªåŒ¹é…çš„ç±»åˆ«

            # âœ… è®°å½•åˆ° wandb.Table
            if args.upload_image:
                image_wandb = wandb.Image(center_image, caption=f"Node {node_id}")  # è½¬æ¢ä¸º WandB æ ¼å¼

                neighbor_images_wandb = []
                if args.neighbor_mode in ["image", "both"] and args.num_neighbours > 0:
                    for i, neighbor_img in enumerate(neighbor_images):
                        neighbor_images_wandb.append(wandb.Image(neighbor_img, caption=f"Neighbor {i+1}"))
                else:
                    neighbor_images_wandb = None  # ä»…æ–‡æœ¬æ¨¡å¼æ—¶ï¼Œä¸åŠ å…¥é‚»å±…å›¾åƒ

                table.add_data(node_id, image_wandb, neighbor_images_wandb, input_text, text_label, prediction, predicted_class if predicted_class else "unknown")
            else:
                table.add_data(node_id, input_text, text_label, prediction, predicted_class if predicted_class else "unknown")


        except Exception as e:
            print(f"Error processing node {node_id}: {str(e)}")

    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = accuracy_score(y_true, y_pred)

    # è®¡ç®— Macro-F1
    macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)

    # è®¡ç®—ä¸åŒ¹é…æ¦‚ç‡
    mismatch_probability = mismatch_count / total_samples

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Macro-F1: {macro_f1:.4f}")
    print(f"Mismatch Probability: {mismatch_probability:.4f}")

    # âœ… å°† Table è®°å½•åˆ° wandb
    wandb.log({"predictions_table": table})

    wandb.log({
        "accuracy": accuracy,
        "macro_f1": macro_f1,
        "mismatch_probability": mismatch_probability
    })

    # ç»“æŸ wandb è¿è¡Œ
    wandb.finish()
    # è®°å½•ç»“æŸæ—¶é—´å¹¶è®¡ç®—è€—æ—¶
    end_time = time.time()
    total_time = end_time - start_time
    print(f"Total time spent: {total_time:.2f} seconds")


if __name__ == "__main__":
    args = parse_args()
    wandb.init(config=args, reinit=True)
    main(args)
